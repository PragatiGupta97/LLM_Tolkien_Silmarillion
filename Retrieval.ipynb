{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lang_funcs import *\n",
    "from langchain.llms import Ollama\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pragatigupta/anaconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      ".gitattributes: 100%|██████████| 1.18k/1.18k [00:00<00:00, 2.33MB/s]\n",
      "1_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 806kB/s]\n",
      "README.md: 100%|██████████| 10.6k/10.6k [00:00<00:00, 6.48MB/s]\n",
      "config.json: 100%|██████████| 612/612 [00:00<00:00, 2.49MB/s]\n",
      "config_sentence_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 563kB/s]\n",
      "data_config.json: 100%|██████████| 39.3k/39.3k [00:00<00:00, 37.8MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:07<00:00, 11.6MB/s]\n",
      "sentence_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 261kB/s]\n",
      "special_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 378kB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 1.77MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 350/350 [00:00<00:00, 3.36MB/s]\n",
      "train_script.py: 100%|██████████| 13.2k/13.2k [00:00<00:00, 25.7MB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 893kB/s]\n",
      "modules.json: 100%|██████████| 349/349 [00:00<00:00, 2.44MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Loading orca-mini from Ollama\n",
    "llm = Ollama(model=\"mistral\", temperature=0)\n",
    "\n",
    "# Loading the Embedding Model\n",
    "embed = load_embedding_model(model_path=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading and splitting the documents\n",
    "docs = load_pdf_data(file_path=\"The_Silmarillion.pdf\")\n",
    "documents = split_docs(documents=docs)\n",
    "\n",
    "# creating vectorstore\n",
    "vectorstore = create_embeddings(documents, embed)\n",
    "\n",
    "# converting vectorstore to a retriever\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "### System:\n",
    "You are an respectful and honest assistant. You have to answer the user's questions using only the context \\\n",
    "provided to you. If you don't know the answer, just say you don't know. Don't try to make up an answer.\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### User:\n",
    "{question}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the prompt from the template which we created before\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Creating the chain\n",
    "chain = load_qa_chain(retriever, llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(retriever, llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pragatigupta/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A Random Forest is an ensemble learning method that consists of a multitude of decision trees,\n",
      "trained using the bagging technique. It introduces extra randomness during tree growing by\n",
      "considering a random subset of features for splitting at each node and using random thresholds. This\n",
      "results in greater tree diversity, which trades a higher bias for a lower variance. The predictions\n",
      "of all the trees in the forest are aggregated to make the final prediction.\n"
     ]
    }
   ],
   "source": [
    "get_response(\"What is random forest?\", chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Aurélien Géron is a Machine Learning consultant and the author of the book \"Hands-On Machine\n",
      "Learning with Scikit-Learn, Keras, and TensorFlow.\" He has worked in various domains including\n",
      "finance, defense, healthcare, and software engineering. He has also published technical books on\n",
      "C++, WiFi, and internet architectures, and was a Computer Science lecturer in a French engineering\n",
      "school. Before his career in technology, he studied microbiology and evolutionary genetics. A few\n",
      "fun facts about him include teaching his children to count in binary and having experienced a\n",
      "parachute malfunction during a jump.\n"
     ]
    }
   ],
   "source": [
    "get_response(\"Who is aurelien geron?\", chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A Voting Classifier is a method of creating an ensemble of classifiers where the final prediction\n",
      "is the class that receives the most votes from all the individual classifiers. This approach, also\n",
      "known as hard voting, can often achieve higher accuracy than any single classifier in the ensemble,\n",
      "even if each classifier is only slightly better than random guessing. The rationale behind this is\n",
      "that by aggregating the predictions of multiple classifiers, the ensemble can make more accurate\n",
      "decisions due to the law of large numbers.\n"
     ]
    }
   ],
   "source": [
    "get_response(\"What is Voting Classifier?\", chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A voting classifier is a method of creating an ensemble classifier by aggregating the predictions\n",
      "of multiple individual classifiers, such as Logistic Regression, SVM, Random Forest, etc., and\n",
      "predicting the class that gets the most votes. This is called a hard voting classifier.  On the\n",
      "other hand, a Random Forest is also an ensemble method, but it consists of a multitude of Decision\n",
      "Trees that operate on various subsets of the data. It uses the bagging technique to train these\n",
      "trees and combines their predictions by taking the average (for regression problems) or the mode\n",
      "(for classification problems). The main difference lies in how the individual classifiers are built\n",
      "and combined.\n"
     ]
    }
   ],
   "source": [
    "get_response(\"What is the difference between voting classifier and random forest?\", chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
